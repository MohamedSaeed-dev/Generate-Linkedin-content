import { Injectable } from '@nestjs/common';
import { ChatGoogleGenerativeAI } from '@langchain/google-genai';
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
} from "@langchain/core/prompts";
import { RunnableWithMessageHistory } from '@langchain/core/runnables';
import { getMessageHistory } from './memory.store.js';
import * as dotenv from 'dotenv'
import { Response } from 'express';
dotenv.config()
const template = `

Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…Ø­ØªØ±Ù ÙÙŠ ÙƒØªØ§Ø¨Ø© Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø¹Ø±Ø¨ÙŠØ© Ù…Ø´ÙˆÙ‚Ø© ÙˆØ¬Ø°Ø§Ø¨Ø© Ø¹Ù„Ù‰ LinkedIn. ÙˆØ¸ÙŠÙØªÙƒ Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù†Ø´ÙˆØ± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©ØŒ ÙŠØªÙ†Ø§ÙˆÙ„ Ù…ÙˆØ¶ÙˆØ¹Ù‹Ø§ Ø¹Ø´ÙˆØ§Ø¦ÙŠÙ‹Ø§ Ø¥Ù…Ø§ ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø®Ø§ØµØ© LLMs) Ø£Ùˆ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø¨Ø§ÙƒÙ†Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NestJS.

âœ… Ø§Ù„Ø´Ø±ÙˆØ·:

Ø§ÙƒØªØ¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø­ÙŠÙˆÙŠ ÙˆÙ…Ø«ÙŠØ±ØŒ Ù…Ø¹ Ù„Ù…Ø³Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© ØªÙ„Ø§Ø¦Ù… Ø¬Ù…Ù‡ÙˆØ± LinkedIn.

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©ØŒ ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¯ÙˆÙ† Ø´Ø±Ø­.

Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ØªØ¬Ø°Ø¨ Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ØŒ ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¯Ø¹ÙˆØ© Ù„Ù„Ù†Ù‚Ø§Ø´ Ø£Ùˆ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¢Ø±Ø§Ø¡.

Ù„Ø§ ØªØ°ÙƒØ± Ø£Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ø´ÙˆØ§Ø¦ÙŠØŒ Ø¨Ù„ Ù‚Ø¯Ù‘Ù…Ù‡ ÙƒÙÙƒØ±Ø© Ù…Ù„Ù‡Ù…Ø© Ø£Ùˆ ØªØ¬Ø±Ø¨Ø© ØªØ³ØªØ­Ù‚ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©.

Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© ğŸ¯ğŸ’¡ğŸš€ ÙˆÙ„ÙƒÙ† Ø¨Ø¯ÙˆÙ† Ø¥ÙØ±Ø§Ø·.

Ø§Ø¬Ø¹Ù„ Ø·ÙˆÙ„ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ (Ù…Ù† 400 Ø¥Ù„Ù‰ 500 ÙƒÙ„Ù…Ø©).

âœ… Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©:

ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù€ LLMs ØªØ­Ø³ÙŠÙ† ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ.

Ø§Ø³ØªØ®Ø¯Ø§Ù… Event-Driven Architecture ÙÙŠ NestJS Ù„ØªÙˆØ³ÙŠØ¹ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©.

Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† RAG Ùˆ Fine-tuning ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ©.

ØªØ¬Ø±Ø¨Ø© Ø¨Ù†Ø§Ø¡ RESTful API Ø¨Ù…Ø³ØªÙˆÙ‰ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NestJS Ùˆ TypeORM.

ğŸ¯ Ø§Ù„Ù‡Ø¯Ù: ØªØ­ÙÙŠØ² Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ† ÙˆØ§Ù„Ù…Ù‡ØªÙ…ÙŠÙ† Ø¨Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù„Ù„ØªÙØ§Ø¹Ù„ØŒ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…Ø¹Ø±ÙØ©ØŒ ÙˆØ¨Ù†Ø§Ø¡ Ù‡ÙˆÙŠØ© Ù…Ù‡Ù†ÙŠØ© Ù‚ÙˆÙŠØ© Ø¹Ù„Ù‰ LinkedIn.


`;

const systemPrompt = SystemMessagePromptTemplate.fromTemplate(template);
const humanPrompt = HumanMessagePromptTemplate.fromTemplate(
  'Question: {question}\nAnswer:',
);

const prompt = ChatPromptTemplate.fromMessages([
  systemPrompt,
  new MessagesPlaceholder('chat_history'),
  humanPrompt,
]);

const model = new ChatGoogleGenerativeAI({
  model: 'gemini-2.0-flash-thinking-exp-01-21',
  maxOutputTokens: 4096,
  temperature: 0.5,
  topP: 0.5,
  apiKey: process.env.GOOGLE_API_KEY,
});

const runnable = prompt.pipe(model);

const chain = new RunnableWithMessageHistory({
  runnable,
  getMessageHistory: getMessageHistory,
  inputMessagesKey: 'question',
  historyMessagesKey: 'chat_history',
});

@Injectable()
export class LlmService {
  async ask(question: string, sessionId: string, res: Response) {
    // res.setHeader('Content-Type', 'text/event-stream');
    // res.setHeader('Cache-Control', 'no-cache');
    // res.setHeader('Connection', 'keep-alive');
    // res.flushHeaders();

    // const stream = await chain.stream({ question }, { configurable: { sessionId } });

    // for await (const chunk of stream) {
    //   res.write(`data: ${JSON.stringify(chunk.content)}\n\n`);
    // }

    // res.write(`event: end\ndata: [DONE]\n\n`);
    // res.end();

     const response = await chain.invoke({ question }, { configurable: { sessionId } });
    return {response :response.content}
  }
}
